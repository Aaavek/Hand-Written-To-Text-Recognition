{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data from csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 32\n",
    "\n",
    "# Load training data from csv file\n",
    "data = pd.read_csv(\"./char_train.csv\")\n",
    "data_t = pd.read_csv(\"./char_test.csv\")\n",
    "\n",
    "# Extract feature columns\n",
    "feature_cols = list(data.columns[1:])\n",
    "feature_cols_t = list(data_t.columns[1:])\n",
    "\n",
    "# Extract target column 'label'\n",
    "target_col = data.columns[0]\n",
    "target_col_t = data_t.columns[0]\n",
    "\n",
    "# Separate the data into feature data and target data (X and y, respectively)\n",
    "X = data[feature_cols]\n",
    "y = data[target_col]\n",
    "X_t = data_t[feature_cols_t]\n",
    "y_t = data_t[target_col_t]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values.reshape(X.shape[0], img_size, img_size, 1)\n",
    "X_t = X_t.values.reshape(X_t.shape[0], img_size, img_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y)\n",
    "y_t = to_categorical(y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_size = 32\n",
    "X = np.array(X,dtype='float32')\n",
    "X = X.astype('float32')\n",
    "y = y.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the models with 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stratkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "models = []\n",
    "\n",
    "for train_index, val_index in stratkf.split(X, np.argmax(y, axis=1)):\n",
    "    X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "    Y_train_fold, Y_val_fold = y[train_index], y[val_index]\n",
    "    \n",
    "    # Create the model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))  # Add more convolutional layers\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))  # Increase the number of neurons in Dense layers\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(52, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    \n",
    "    model.fit(X_train_fold, Y_train_fold, epochs=15, batch_size=100, validation_data=(X_val_fold, Y_val_fold))\n",
    "    \n",
    "    score = model.evaluate(X_val_fold, Y_val_fold, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y_pred = []\n",
    "\n",
    "for model in models:\n",
    "    y_pred = model.predict(X_t)\n",
    "    Y_pred.append(y_pred)\n",
    "    \n",
    "\n",
    "Y_pred = np.array(Y_pred)\n",
    "Y_pred = np.argmax(Y_pred, axis=2)\n",
    "\n",
    "\n",
    "Y_pred = np.transpose(Y_pred)\n",
    "\n",
    "Y_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=1, arr=Y_pred)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(np.argmax(y_t, axis=1), Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving models locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, model in enumerate(models):\n",
    "    model.save(\"./models/model_\"+str(i)+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = []\n",
    "\n",
    "for i in range(5):\n",
    "    # Loading model\n",
    "    model = load_model(\"./models/model_\"+str(i)+\".h5\")\n",
    "    loaded_model.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction and Generating Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    loaded_model = []\n",
    "\n",
    "    for i in range(5):\n",
    "        # Loading model\n",
    "        model = load_model(\"./models/model_\"+str(i)+\".h5\")\n",
    "        loaded_model.append(model)\n",
    "    return loaded_model\n",
    "\n",
    "def predict(models, X_t):\n",
    "    Y_pred = []\n",
    "\n",
    "    for model in models:\n",
    "        y_pred = model.predict(X_t)\n",
    "        Y_pred.append(y_pred)\n",
    "\n",
    "\n",
    "    Y_pred = np.array(Y_pred)\n",
    "    Y_pred = np.argmax(Y_pred, axis=2)\n",
    "\n",
    "\n",
    "    Y_pred = np.transpose(Y_pred)\n",
    "\n",
    "    Y_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=1, arr=Y_pred)\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = predict(models, X_t)\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(np.argmax(y_t, axis=1), Y_pred)\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix).plot()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
