{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = -1\n",
    "def load_images_from_folder(folder):\n",
    "    images = {}\n",
    "    for filename in os.listdir(folder)[:sample_size]:\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images[filename] = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segments(name,image):\n",
    "\n",
    "    if image is None:\n",
    "        print(\"Could not read the image.\")\n",
    "        return 0\n",
    "    # Preprocess the image (e.g., apply Gaussian blur)\n",
    "    image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "    # Apply adaptive thresholding\n",
    "    image = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 10)\n",
    "\n",
    "    # Perform adaptive dilation\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Customize the kernel size based on the image dimensions and line characteristics\n",
    "    kernel_height = 1  # Adjust as needed\n",
    "    kernel_width = int(width)    # Adjust as needed\n",
    "    kernel = np.full((kernel_height, kernel_width),255, np.uint8)\n",
    "    img_dilation = cv2.dilate(image, kernel, iterations=10)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(img_dilation, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if not contours:\n",
    "        print(\"No contours found.\")\n",
    "        return 0\n",
    "\n",
    "    if len(contours) == 1:\n",
    "        # Get bounding box\n",
    "        x, y, w, h = cv2.boundingRect(contours[0])\n",
    "        # Extract ROI\n",
    "        roi = image[y:y + h, x:x + w]\n",
    "        # Save and display ROI\n",
    "        images[name] = roi\n",
    "\n",
    "        if not os.path.exists('words_dataset'):\n",
    "            os.makedirs('words_dataset')\n",
    "        \n",
    "        for f in os.listdir('words_dataset'):\n",
    "            if os.path.isfile('words_dataset/'+f): \n",
    "                os.remove('words_dataset/'+f)\n",
    "            elif os.path.isdir('words_dataset/'+f):\n",
    "                shutil.rmtree('words_dataset/'+f)\n",
    "\n",
    "        cv2.imwrite('words_dataset/'+ name,255 - roi)\n",
    "\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330961\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "No contours found.\n",
      "27747\n"
     ]
    }
   ],
   "source": [
    "# segmenting lines\n",
    "images = load_images_from_folder('dataset')\n",
    "filenames = os.listdir('dataset')\n",
    "print(len(filenames))\n",
    "\n",
    "for name in filenames[:sample_size]:\n",
    "    get_segments(name,images.pop(name))\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the CSV file\n",
    "labels = {}\n",
    "chars_labels = {}\n",
    "with open('written_name_train_v2.csv', 'r') as file:\n",
    "    # Create a CSV reader object\n",
    "    csv_reader = csv.reader(file)\n",
    "\n",
    "    # Iterate over each row in the CSV file\n",
    "    for row in csv_reader:\n",
    "        # Access data in each row\n",
    "        if row[0] in images.keys():\n",
    "            labels[row[0]] = str(row[1]).replace(\" \",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_characters(name, segment):\n",
    "    if len(segment.shape) == 3:\n",
    "        segment = cv2.cvtColor(segment, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    _, segment = cv2.threshold(segment, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours in the binary image\n",
    "    contours, _ = cv2.findContours(segment, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Sort contours based on x-coordinate\n",
    "    contours = sorted(contours, key=lambda c: cv2.boundingRect(c)[0])\n",
    "    if len(contours) != len(labels[name]):\n",
    "        return 0\n",
    "\n",
    "    # heights = [cv2.boundingRect(contour)[3] for contour in contours]\n",
    "    # avgheight = sum(heights)/len(heights)\n",
    "    \n",
    "    # widths = [cv2.boundingRect(contour)[2] for contour in contours]\n",
    "    # avgwidth = sum(widths)/len(widths)\n",
    "\n",
    "    factor = 1\n",
    "    prev_end = None\n",
    "    \n",
    "    # Iterate through each contour (presumed to be a character) and save as individual images\n",
    "    for i, contour in enumerate(contours):\n",
    "\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "        # Ignore contours that are too small\n",
    "\n",
    "        # if w < avgwidth/10 and h < avgheight/10:\n",
    "        #     continue\n",
    "\n",
    "        # if prev_end is None:\n",
    "        #     prev_end = x + w\n",
    "\n",
    "        # if x > prev_end + factor * avgwidth:\n",
    "        #     print(\"Space detected\")\n",
    "\n",
    "        character_image = segment[y:y + h, x:x + w]\n",
    "\n",
    "        # color to Gray scale character_image\n",
    "                \n",
    "        cv2.imwrite('chars_dataset/'+str(i)+name, 255 - character_image)\n",
    "        chars[str(i)+name] = np.where(character_image > 50 , 0,1)\n",
    "        chars_labels[str(i)+name] = labels[name][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68751\n"
     ]
    }
   ],
   "source": [
    "chars = {}\n",
    "for name in images.keys():\n",
    "    segment_characters(name,images[name])\n",
    "print(len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfile = 'char_train.csv'\n",
    "testfile = 'char_test.csv'\n",
    "\n",
    "# the height and width of our final image\n",
    "fnl_hyt = 100\n",
    "fnl_wdt = 100\n",
    "pad_value = 1\n",
    "\n",
    "if(os.path.exists(trainfile) and os.path.isfile(trainfile)): \n",
    "  os.remove(trainfile) \n",
    "if(os.path.exists(testfile) and os.path.isfile(testfile)): \n",
    "  os.remove(testfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(image):\n",
    "    img_wdt = len(image[0])\n",
    "    img_hyt = len(image)\n",
    "    non_white_pixels = np.argwhere(image != pad_value)\n",
    "\n",
    "    top_mrgn = 0\n",
    "    bot_mrgn = img_hyt-1\n",
    "    left_mrgn = 0\n",
    "    right_mrgn = img_wdt-1\n",
    "\n",
    "    # method 1****************************************************\n",
    "\n",
    "    top_mrgn, left_mrgn = non_white_pixels.min(axis=0)\n",
    "    bot_mrgn, right_mrgn = non_white_pixels.max(axis=0)\n",
    "\n",
    "    # method 2*****************************************************\n",
    "    # for i in range(img_hyt):\n",
    "    #     if crop_cond(image[i]):\n",
    "    #         top_mrgn = i\n",
    "    #         break\n",
    "    \n",
    "    # for i in range(img_hyt):\n",
    "    #     if crop_cond(image[img_hyt - i - 1]):\n",
    "    #         bot_mrgn = img_hyt - i - 1\n",
    "    #         break\n",
    "    \n",
    "    # t_image = image.T\n",
    "    # for i in range(img_wdt):\n",
    "    #     if crop_cond(t_image[i]):\n",
    "    #         left_mrgn = i\n",
    "    #         break\n",
    "    \n",
    "    # for i in range(img_wdt):\n",
    "    #     if crop_cond(t_image[img_wdt - i - 1]):\n",
    "    #         bot_mrgn = img_wdt - i - 1\n",
    "    #         break\n",
    "    \n",
    "    return image[top_mrgn:bot_mrgn+1 , left_mrgn:right_mrgn+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the value which we are padding\n",
    "def pad(image):\n",
    "    img_hyt = len(image)\n",
    "    img_wdt = len(image[0])\n",
    "\n",
    "    pad_hyt = img_hyt\n",
    "    pad_wdt = img_wdt\n",
    "\n",
    "    while(pad_hyt%10 != 0):\n",
    "        pad_hyt += 1\n",
    "\n",
    "    while(pad_wdt%10 != 0):\n",
    "        pad_wdt += 1\n",
    "\n",
    "    if pad_wdt > pad_hyt:\n",
    "        pad_hyt = pad_wdt\n",
    "    else :\n",
    "        pad_wdt = pad_hyt\n",
    "    \n",
    "    top_pad = np.zeros(((pad_hyt-img_hyt)//2, img_wdt)) + pad_value\n",
    "    bot_pad = np.zeros(((pad_hyt-img_hyt+1)//2 , img_wdt)) + pad_value\n",
    "    left_pad = np.zeros((pad_hyt, (pad_wdt-img_wdt)//2)) + pad_value\n",
    "    right_pad = np.zeros((pad_hyt, (pad_wdt-img_wdt+1)//2)) + pad_value\n",
    "\n",
    "    # Stack the padding arrays and the image\n",
    "    return np.hstack((left_pad, np.vstack((top_pad, image,bot_pad)) ,right_pad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import zoom  \n",
    "def reshape(image):\n",
    "    return np.where(zoom(image,(fnl_hyt/len(image), fnl_wdt/len(image[0])) , order = 1) > 0.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(image, avg):\n",
    "    int_fill = 1 - (np.sum(image) / (image.shape[0] * image.shape[1]))\n",
    "    fill = int_fill\n",
    "\n",
    "    if fill > avg :\n",
    "        while fill > avg:\n",
    "            change = np.argwhere((image - np.roll(image, 1, axis=0)) +\n",
    "                                (image - np.roll(image, 1, axis=1)) +\n",
    "                                (image - np.roll(image, -1, axis=0)) +\n",
    "                                (image - np.roll(image, -1, axis=1)) < 0)\n",
    "\n",
    "            image[change[:, 0], change[:, 1]] = pad_value\n",
    "            tfill = 1 - (np.sum(image) / (image.shape[0] * image.shape[1]))\n",
    "\n",
    "            if tfill >= fill:\n",
    "                raise ValueError(\"Error: Unable to trim the image further.\")\n",
    "\n",
    "            fill = tfill\n",
    "    \n",
    "    else :\n",
    "        image = 1 - image\n",
    "        fill = 1 - fill\n",
    "        while fill >= 1 - avg:\n",
    "            change = np.argwhere((image - np.roll(image, 1, axis=0)) +\n",
    "                                (image - np.roll(image, 1, axis=1)) +\n",
    "                                (image - np.roll(image, -1, axis=0)) +\n",
    "                                (image - np.roll(image, -1, axis=1)) < 0)\n",
    "\n",
    "            image[change[:, 0], change[:, 1]] = pad_value\n",
    "            tfill = 1 - (np.sum(image) / (image.shape[0] * image.shape[1]))\n",
    "\n",
    "            if tfill >= fill:\n",
    "                raise ValueError(\"Error: Unable to trim the image further.\")\n",
    "\n",
    "            fill = tfill\n",
    "        image = 1 - image\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(image):\n",
    "    return reshape(pad(crop(image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68751\n",
      "0.23988900670535698\n",
      "0.240473864597614\n"
     ]
    }
   ],
   "source": [
    "transformed_chars = {}\n",
    "for name in chars.keys():\n",
    "    transformed_chars[name] = transform(chars[name])\n",
    "    # print(transformed_chars[name].shape)\n",
    "\n",
    "print(len(transformed_chars))\n",
    "\n",
    "fill_avg = []\n",
    "for name in chars.keys():\n",
    "    fill_avg.append(1- (np.sum(transformed_chars[name])/(transformed_chars[name].shape[0]*transformed_chars[name].shape[1])))\n",
    "    \n",
    "avg = np.mean(np.array(fill_avg))\n",
    "print(avg)\n",
    "\n",
    "if not os.path.exists('processesed_dataset'):\n",
    "        os.makedirs('processesed_dataset')\n",
    "        \n",
    "for f in os.listdir('processesed_dataset'):\n",
    "    if os.path.isfile('processesed_dataset/'+f): \n",
    "        os.remove('processesed_dataset/'+f)\n",
    "    elif os.path.isdir('processesed_dataset/'+f):\n",
    "        shutil.rmtree('processesed_dataset/'+f)\n",
    "for name in chars.keys():\n",
    "    if chars_labels[name] == '-':\n",
    "        chars_labels.pop(name)\n",
    "        transformed_chars.pop(name)\n",
    "        continue\n",
    "    \n",
    "    transformed_chars[name] = trim(transformed_chars[name],avg)\n",
    "    output_folder = 'processesed_dataset/'+chars_labels[name]\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    cv2.imwrite(output_folder+'/'+name, transformed_chars[name]*255)\n",
    "\n",
    "\n",
    "fill_avg = []\n",
    "for name in transformed_chars.keys():\n",
    "    fill_avg.append(1- (np.sum(transformed_chars[name])/(transformed_chars[name].shape[0]*transformed_chars[name].shape[1])))\n",
    "    \n",
    "avg = np.mean(np.array(fill_avg))\n",
    "print(avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(len(transformed_chars),len(transformed_chars)*8//10,replace=False)\n",
    "names = transformed_chars.keys()\n",
    "\n",
    "with open(trainfile, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([i for i in range(fnl_hyt*fnl_wdt + 1)])\n",
    "\n",
    "    for i,name in enumerate(names):\n",
    "        if i in idx:\n",
    "            writer.writerow([ord(chars_labels[name])] + list(transformed_chars[name].flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "with open(testfile, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([i for i in range(fnl_hyt*fnl_wdt + 1)])\n",
    "\n",
    "    for i,name in enumerate(names):\n",
    "        if i not in idx:\n",
    "            writer.writerow([ord(chars_labels[name])] + list(transformed_chars[name].flatten()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
